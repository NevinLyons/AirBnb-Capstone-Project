{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nevin in suit pt 1.jpg\" style=\"float: right; margin: 20px; height: 150px\">\n",
    "\n",
    "# AirBnb Analysis -> Capstone Project\n",
    "\n",
    "_Author: Nevin Joshua Lyons_\n",
    "\n",
    "---\n",
    "\n",
    ">Basing my Capstone Project on the CRISP-DM model based on the Data Science Analytics Methodology. CRISP-DM stands for Cross-Industry Standard Process for Data Mining. \n",
    "\n",
    "\n",
    "- **CR**oss\n",
    "- **I**ndustry\n",
    "- **S**tandard\n",
    "- **P**rocess\n",
    "- **D**ata\n",
    "- **M**ining\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. An executive summary:\n",
    "  - What is your goal?\n",
    "  \n",
    "The goal of the project is to conduct sentiment analysis on Airbnb guest reviews to identify factors influencing guest satisfaction and dissatisfaction. The objective is to provide actionable recommendations for listing improvement based on insights derived from the sentiment analysis\n",
    "\n",
    "  - Where did you get your data?\n",
    "  \n",
    "Kaggle Source  \n",
    "\n",
    "  - What are your metrics?\n",
    "  \n",
    "The primary metrics used for the sentiment analysis include sentiment polarity scores, which indicate the positivity or negativity of each review. Additionally, sentiment trends for different aspects of listings such as cleanliness, location, amenities, and host responsiveness are analyzed to identify areas for improvement.\n",
    "\n",
    "  - What were your findings?\n",
    "  \n",
    "To be done soon\n",
    "\n",
    "  - What risks/limitations/assumptions affect these findings?\n",
    "  \n",
    "**Data Quality**: The accuracy and reliability of sentiment analysis findings depend on the quality of the data, including the completeness and authenticity of guest reviews.\n",
    "\n",
    "**Subjectivity**: Sentiment analysis is inherently subjective and may vary based on individual interpretation, cultural differences, and context. It's essential to acknowledge the inherent subjectivity in analyzing guest sentiment.\n",
    "\n",
    "**Sample Bias**: The dataset may exhibit sample bias, with reviews being more likely to be submitted by guests with particularly positive or negative experiences. This bias could affect the generalizability of findings to all Airbnb guests.\n",
    "\n",
    "**Assumptions**: The analysis assumes that guest reviews accurately reflect the overall guest experience and that addressing identified areas for improvement will lead to enhanced guest satisfaction and improved listing performance. However, there may be other factors influencing guest satisfaction that are not captured in the data.\n",
    "\n",
    "2. Summarize your statistical analysis, including:\n",
    "  - implementation\n",
    "  - evaluation\n",
    "  - inference\n",
    "3. Clearly document and label each section of your notebook(s)\n",
    "  - Logically organize your information in a persuasive, informative manner.\n",
    "  - Include notebook headers and subheaders, as well as clearly formatted markdown for all written components.\n",
    "  - Include graphs/plots/visualizations with clear labels.\n",
    "  - Comment and explain the purpose of each major section/subsection of your code.\n",
    "  - Document your code for your future self, as if another person needed to replicate your approach.\n",
    "4. Clearly document all of your decision points in the relevant sections\n",
    "  - How did you acquire your data?\n",
    "  - How did you transform or engineer your data?  Why?\n",
    "  - How did you select your model?\n",
    "  - How did you optimize hyperparameters?\n",
    "5. Host your notebook and any other materials in your own public Github Repository.\n",
    "  - You repo should have README file that guides us through the repository and links to important files.\n",
    "  - Include links and explanations to any outside libraries or source code used.\n",
    "  - Host a copy of your dataset or include a link to a remotely hosted version.\n",
    "\n",
    "**BONUS**\n",
    "\n",
    "Create a medium post of at least 1,000 words summarizing your approach in a tutorial format and link to it in your notebook.  In your tutorial, address a slightly less technical audience. Think back to Day 1 of the program - how would you explain and walk through your capstone project to your earlier self?\n",
    "\n",
    "\n",
    "Exploratory data analysis (EDA) is a crucial part of any data science project. EDA helps us discover interesting relationships in the data, detect outliers and errors, examine our own assumptions about the data, and prepare for modeling. During EDA we might discover that we need to clean our data more conscientiously, or that we have more missing data than we realized, or that there aren't many patterns in the data (indicating that modeling may be challenging.)\n",
    "\n",
    "In this lab you'll bring in a natural language dataset and perform EDA. The dataset contains Facebook statuses taken from between 2009 and 2011 as well as personality test results associated with the users whose Facebook statuses are included.\n",
    "\n",
    "This dataset uses results from the Big Five Personality Test, also referred to as the five-factor model, which measures a person's score on five dimensions of personality:\n",
    "- **O**penness\n",
    "- **C**onscientiousness\n",
    "- **E**xtroversion\n",
    "- **A**greeableness\n",
    "- **N**euroticism\n",
    "\n",
    "Notoriously, the political consulting group Cambridge Analytica claims to have predicted the personalities of Facebook users by using those users' data, with the goal of targeting them with political ads that would be particularly persuasive given their personality type. Cambridge Analytica claims to have considered 32 unique 'groups' in the following fashion:\n",
    "- For each of the five OCEAN qualities, a user is categorized as either 'yes' or 'no'.\n",
    "- This makes for 32 different potential combinations of qualities. ($2^5 = 32$).\n",
    "\n",
    "Cambridge Analytica's methodology was then, roughly, the following:\n",
    "- Gather a large amount of data from Facebook.\n",
    "- Use this data to predict an individual's Big Five personality \"grouping.\"\n",
    "- Design political advertisements that would be particularly effective to that particular \"grouping.\" (For example, are certain advertisements particularly effective toward people with specific personality traits?)\n",
    "\n",
    "In this lab you will perform EDA to examine many relationships in the data.\n",
    "\n",
    "Exploratory data analysis can be a non-linear process, and you're encouraged to explore questions that occur to you as you work through the notebook.\n",
    "\n",
    "> **Content note**: This dataset contains real Facebook statuses scraped from 2009 to 2011, and some of the statuses contain language that is not safe for work, crude, or offensive. The full dataset is available as `mypersonality.csv`, and a sanitized version containing only statuses that passed an automated profanity check is available as `mypersonality_noprofanity.csv`. Please do not hesitate to use `mypersonality_noprofanity.csv` if you would prefer to. Please note that the automated profanity check is not foolproof. If you have any concerns about working with this dataset, please get in touch with your section lead.\n",
    "\n",
    "---\n",
    "\n",
    "### External resources\n",
    "\n",
    "These resources are not required reading but may be of use or interest.\n",
    "\n",
    "- [Python Graph Gallery](https://python-graph-gallery.com/)\n",
    "- [Wikipedia page](https://en.wikipedia.org/wiki/Big_Five_personality_traits) on the Big Five test\n",
    "- [A short (3-4 pages) academic paper](./celli-al_wcpr13.pdf) using the `MyPersonality` dataset to model personality\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Cleaning the data Types of data need to clean:\n",
    "\n",
    "- Missing Values\n",
    "- Data Type Conversion\n",
    "- Inconsistent Formatting\n",
    "- Duplicate Data\n",
    "- Inaccurate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# this setting widens how many characters pandas will display in a column:\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('calendar.csv')\n",
    "listings = pd.read_csv('listings.csv')\n",
    "reviews = pd.read_csv('reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>t</td>\n",
       "      <td>$85.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        date available   price\n",
       "0      241032  2016-01-04         t  $85.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id         0\n",
       "date               0\n",
       "available          0\n",
       "price         459028\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241032</td>\n",
       "      <td>https://www.airbnb.com/rooms/241032</td>\n",
       "      <td>20160104002432</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Stylish Queen Anne Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Make your self at home in this charming one-bedroom apartment, centrally-located on the west side of Queen Anne hill.   This elegantly-decorated, completely private apartment (bottom unit of a duplex) has an open floor plan, bamboo floors, a fully equipped kitchen, a TV,  DVD player, basic cable, and a very cozy bedroom with a queen-size bed. The unit sleeps up to four (two in the bedroom and ...</td>\n",
       "      <td>Make your self at home in this charming one-bedroom apartment, centrally-located on the west side of Queen Anne hill.   This elegantly-decorated, completely private apartment (bottom unit of a duplex) has an open floor plan, bamboo floors, a fully equipped kitchen, a TV,  DVD player, basic cable, and a very cozy bedroom with a queen-size bed. The unit sleeps up to four (two in the bedroom and ...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          listing_url       scrape_id last_scraped  \\\n",
       "0  241032  https://www.airbnb.com/rooms/241032  20160104002432   2016-01-04   \n",
       "\n",
       "                           name summary  \\\n",
       "0  Stylish Queen Anne Apartment     NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                             space  \\\n",
       "0  Make your self at home in this charming one-bedroom apartment, centrally-located on the west side of Queen Anne hill.   This elegantly-decorated, completely private apartment (bottom unit of a duplex) has an open floor plan, bamboo floors, a fully equipped kitchen, a TV,  DVD player, basic cable, and a very cozy bedroom with a queen-size bed. The unit sleeps up to four (two in the bedroom and ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                       description  \\\n",
       "0  Make your self at home in this charming one-bedroom apartment, centrally-located on the west side of Queen Anne hill.   This elegantly-decorated, completely private apartment (bottom unit of a duplex) has an open floor plan, bamboo floors, a fully equipped kitchen, a TV,  DVD player, basic cable, and a very cozy bedroom with a queen-size bed. The unit sleeps up to four (two in the bedroom and ...   \n",
       "\n",
       "  experiences_offered neighborhood_overview  ... review_scores_value  \\\n",
       "0                none                   NaN  ...                10.0   \n",
       "\n",
       "  requires_license license jurisdiction_names instant_bookable  \\\n",
       "0                f     NaN         WASHINGTON                f   \n",
       "\n",
       "  cancellation_policy  require_guest_profile_picture  \\\n",
       "0            moderate                              f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              2   \n",
       "\n",
       "  reviews_per_month  \n",
       "0              4.07  \n",
       "\n",
       "[1 rows x 92 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "listing_url                           0\n",
       "scrape_id                             0\n",
       "last_scraped                          0\n",
       "name                                  0\n",
       "                                   ... \n",
       "cancellation_policy                   0\n",
       "require_guest_profile_picture         0\n",
       "require_guest_phone_verification      0\n",
       "calculated_host_listings_count        0\n",
       "reviews_per_month                   627\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to everything!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     7202016  38917982  2015-07-19     28943674        Bianca   \n",
       "\n",
       "                                                comments  \n",
       "0  Cute and cozy place. Perfect location to everything!   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84849 entries, 0 to 84848\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   listing_id     84849 non-null  int64 \n",
      " 1   id             84849 non-null  int64 \n",
      " 2   date           84849 non-null  object\n",
      " 3   reviewer_id    84849 non-null  int64 \n",
      " 4   reviewer_name  84849 non-null  object\n",
      " 5   comments       84831 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.isnull().sum()\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EDA on Statuses\n",
    "\n",
    "Before we even vectorize the text, we might look at the lengths and word counts in each Facebook status.\n",
    "\n",
    "#### Create a new column called `status_length` that contains the length of each status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>status_length</th>\n",
       "      <th>status_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she can't get to sleep.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the base of her neck to stop hurting. On the other hand, YAY I'M IN ILLINOIS! &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/15/09 01:15 PM</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/22/09 04:48 AM</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/20/09 02:31 AM</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                                                                                                      STATUS  \\\n",
       "0                                                                                                likes the sound of thunder.   \n",
       "1                                                            is so sleepy it's not even funny that's she can't get to sleep.   \n",
       "2  is sore and wants the knot of muscles at the base of her neck to stop hurting. On the other hand, YAY I'M IN ILLINOIS! <3   \n",
       "3                                                                                 likes how the day sounds in this new song.   \n",
       "4                                                                                                                is home. <3   \n",
       "\n",
       "   sEXT  sNEU  sAGR  sCON  sOPN cEXT cNEU cAGR cCON cOPN               DATE  \\\n",
       "0  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/19/09 03:21 PM   \n",
       "1  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  07/02/09 08:41 AM   \n",
       "2  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/15/09 01:15 PM   \n",
       "3  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/22/09 04:48 AM   \n",
       "4  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  07/20/09 02:31 AM   \n",
       "\n",
       "   status_length  status_word_count  \n",
       "0             27                 27  \n",
       "1             63                 63  \n",
       "2            121                121  \n",
       "3             42                 42  \n",
       "4             11                 11  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'statuses_df' containing the Facebook statuses\n",
    "# and the column 'status' containing the text of each status\n",
    "# You can create the 'status_length' column as follows:\n",
    "\n",
    "# Calculate the length of each status and store it in a new column\n",
    "df['status_length'] = df['STATUS'].apply(len)\n",
    "\n",
    "# Display the DataFrame to verify the new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sent_tokenize(reviews())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "sent_tokenize(reviews())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new column called `status_word_count` that contains the number of words in each status:\n",
    "\n",
    "Note: You can evaluate this based off of how many strings are separated by whitespaces; you're not required to check that each set of characters set apart by whitespaces is a word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            #AUTHID  \\\n",
      "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
      "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
      "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
      "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
      "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
      "\n",
      "                                                                                                                      STATUS  \\\n",
      "0                                                                                                likes the sound of thunder.   \n",
      "1                                                            is so sleepy it's not even funny that's she can't get to sleep.   \n",
      "2  is sore and wants the knot of muscles at the base of her neck to stop hurting. On the other hand, YAY I'M IN ILLINOIS! <3   \n",
      "3                                                                                 likes how the day sounds in this new song.   \n",
      "4                                                                                                                is home. <3   \n",
      "\n",
      "   sEXT  sNEU  sAGR  sCON  sOPN cEXT cNEU cAGR cCON cOPN               DATE  \\\n",
      "0  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/19/09 03:21 PM   \n",
      "1  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  07/02/09 08:41 AM   \n",
      "2  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/15/09 01:15 PM   \n",
      "3  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  06/22/09 04:48 AM   \n",
      "4  2.65   3.0  3.15  3.25   4.4    n    y    n    n    y  07/20/09 02:31 AM   \n",
      "\n",
      "   status_length  status_word_count  \n",
      "0             27                 27  \n",
      "1             63                 63  \n",
      "2            121                121  \n",
      "3             42                 42  \n",
      "4             11                 11  \n"
     ]
    }
   ],
   "source": [
    "df['status_word_count'] = df['STATUS'].apply(len)\n",
    "\n",
    "# Display the DataFrame to verify the new column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest and shortest statuses\n",
    "\n",
    "Looking at individual observations can help us get a sense of what the dataset contains.\n",
    "\n",
    "#### Show the five longest and five shortest statuses based off of `status_word_count`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five longest statuses:\n",
      "8026    Heh...:\"God I wish that I could hide away//And find a wall to bang my brains//I'm living in a fantasy,//a nightmare dream...reality//People ride about all day//In metal boxes made away//I wish that they would drop the bomb//And kill these cunts//that don't belong! I hate people!//I hate the human race//I hate people!//I hate your ugly face//I hate people!//I hate your fucking mess//I hate peop...\n",
      "7976    \"I said he's a fairy I do suppose//flyin thru the air in pantyhose//he may be very sexy or even cute//but he looks like a sucka in a blue and red suit//I said you need a man who's got finesse//& his whole name across his chest//he may be able to fly all thru the night//but can he rock a party til the early light//he can't satisfy you with his little worm//but I can bust you out w my Super sper...\n",
      "9651    - so, this morning *PROPNAME* gets up to play and he goes over to the carpet where the light was shining through the blinds casting shadows...he then proceeds to tell me the different letters the sun is making on the carpet... 'I', 'T' and 'L' to be exact! He then somehow figured out how to cast his shadow over the sun to make the letters change & disappear! At this rate, he will be smarter th...\n",
      "5208    can't believe it. I got the new Wii Fit Plus game, it has a lot of fun new games and features. However, after not using the wii fit for a few months we decided to do the fitness test stuff again. Me(since last time): +2.9 lbs, still a healthy weight and BMI, wii age 54. *PROPNAME*: -8.6lbs, reccommends a healthy weight of gaining 6lbs, wii age 32. On the positive side, I have lost 5 of the 8 l...\n",
      "7605    Define me urban dictionary \"The Most wonderful person in the World. Kind, Sweet, Loving, Caring, Gentle. Perfect in Every way. The one you love for all your life. Crazy hot girl. Beautiful, smart & funny; *PROPNAME* posesses atributes absent in 99.9% of women. Truly a lucky find. Plus she rocks. The most wonderful drug in the world, better know as lortab. taking the pill may cause a sense of e...\n",
      "Name: STATUS, dtype: object\n",
      "\n",
      "Five shortest statuses:\n",
      "26      <3\n",
      "1766    <3\n",
      "2120    15\n",
      "3280    :(\n",
      "6851    ):\n",
      "Name: STATUS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named df\n",
    "# Replace 'status_word_count' with the actual column name containing word counts\n",
    "# Replace 'status' with the actual column name containing statuses\n",
    "\n",
    "# Longest statuses\n",
    "longest_statuses = df.nlargest(5, 'status_word_count')['STATUS']\n",
    "\n",
    "# Shortest statuses\n",
    "shortest_statuses = df.nsmallest(5, 'status_word_count')['STATUS']\n",
    "\n",
    "print(\"Five longest statuses:\")\n",
    "print(longest_statuses)\n",
    "\n",
    "print(\"\\nFive shortest statuses:\")\n",
    "print(shortest_statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the distribution of post lengths?\n",
    "\n",
    "Use visuals to show the distributions of post lengths. Show both the distribution of word counts and the distribution of lengths based off character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EDA of Personality Scores\n",
    "\n",
    "There are two sets of personality columns in the dataset: class and score. According to the attached paper, scores have been converted to categories based on whether a score for a user fell above or below the median.\n",
    "\n",
    "### Plot the distributions of personality scores for all five score columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### How many unique users exist in the dataset?\n",
    "\n",
    "This dataset has redacted original poster names, but each user is given an `#AUTHID`. How many unique users are there, and how many posts per user do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on unique users\n",
    "\n",
    "Because we have many posts per user for most users, doing EDA on the personality score columns might be misleading. If we have 200 Facebook statuses from one very high-conscientiousness user, a bar chart of how many `'cCON'` statuses are associated with `'y'` might be misleading. We'll have to be careful about labeling and titling any visualizations we make off of the dataset.\n",
    "\n",
    "#### Create a new dataframe called `unique_users` that only contains the `#AUTHID`, personality score, and personality category columns:\n",
    "\n",
    "If you do this correctly, it should have 250 rows and 11 columns.\n",
    "\n",
    "(Hint: You can use the pandas [drop_duplicates()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html) method to make this easier. The only column you want to consider when deciding if a user is duplicated is the `#AUTHID` column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution of personality scores for `unique_users`:\n",
    "\n",
    "Do the distributions look different? Here, each individual user will only be represented once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `.describe()` method on `unique_users`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots vs. Tables\n",
    "\n",
    "Consider what different information is easily conveyed by the plots of scores, versus the table with summary statistics. Explain when you might present a distribution versus when you might present a table of summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other visualizations:\n",
    "\n",
    "Create 1-2 additional visualizations related to the `unique_users` dataframe.\n",
    "\n",
    "You might consider:\n",
    "- Barcharts of users per category per trait\n",
    "- A seaborn correlation heatmap\n",
    "- A seaborn pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploring status length and word count based on personality\n",
    "\n",
    "#### Using `groupby()`, find the mean status length and status word count for posts by users in the high and low categories of each of the Big 5 traits.\n",
    "\n",
    "You'll need to use `groupby()` five separate times for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose one of the personality category columns (i.e. `cOPN`, `cCON`, `cEXT`, `cAGR`, or `cNEU`.) Use `sns.distplot()` to visualize the distribution of status word counts for posts by users who score both high (`y`) and low (`n`) in that personality category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## EDA on Word Counts\n",
    "\n",
    "### Vectorize the text\n",
    "\n",
    "In order to perform EDA on word count data, we'll need to count-vectorize.\n",
    "\n",
    "Create a dataframe that contains the count-vectorized text for each Facebook status in the dataset.\n",
    "\n",
    "To do this, you might follow these steps:\n",
    "- Instantiate a `CountVectorizer` object\n",
    "- Fit the count vectorizer on the Facebook statuses\n",
    "- Store the transformed data\n",
    "- Convert to a dataframe and store\n",
    "    - Don't forget that the transformed data will need to be 'densified'. The `toarray()` or `todense()` methods will allow this.\n",
    "    - Don't forget that the `get_feature_names()` method on a fitted `CountVectorizer` object will bring you back the words learned from the dataset, which you can set as the `columns` argument when creating the dataframe.\n",
    "    \n",
    "It's up to you whether or not to keep stopwords in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the 15 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the 15 frequency of the most common words as a bar chart\n",
    "\n",
    "**Hint**: You can do this in one line of code. [This webpage](https://dfrieds.com/data-visualizations/bar-plot-python-pandas.html) has an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating `propname`\n",
    "\n",
    "The word `propname` shows up frequently in this dataset. Show the first 10 statuses in the dataset that contain `propname`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide a short explanation of what you believe `propname` to be:\n",
    "\n",
    "Hint: The attached PDF also contains an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words based on personality category\n",
    "\n",
    "In order to do more targeted EDA, we'll need to be able to reference not only the dataframe of vectorized statuses, but also the personality scores from the original dataframe.\n",
    "\n",
    "#### Create a new dataframe called `text_and_scores` that concatenates the count-vectorized statuses side-by-side with the original personality category columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the 25 most common words for statuses from high-cAGR users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the 25 most common words for statuses from low-cAGR users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (BONUS) Most common bigrams:\n",
    "\n",
    "This is a bonus section and not required.\n",
    "\n",
    "Find the 10 most common bigrams in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (BONUS) Most common trigrams:\n",
    "\n",
    "This is a bonus section and not required.\n",
    "\n",
    "Find the 10 most common trigrams in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Choose your own adventure\n",
    "\n",
    "By now you've looked at a lot of visualizations and frequency counts.\n",
    "\n",
    "Come up with 2-3 questions about the data, and try to answer them using descriptive statistics (like counts, averages, etc.) or visualizations.\n",
    "\n",
    "Some questions you might explore:\n",
    "- Have numbers been redacted, or are phone numbers, house numbers, or zip codes anywhere in the dataset?\n",
    "- `PROPNAME` has been used to redact personal names. Given that this data was scraped between 2009 and 2011, investigate if any public figures or famous people show up in the dataset, or their names have been redacted as well.\n",
    "- Is count of uppercase letters vs. lowercase letters per status related to any personality category or personality score?\n",
    "- Is _average_ word count per status related to any personality category or personality metric?\n",
    "- Is punctuation use related to personality?\n",
    "\n",
    "Or, of course, come up with your own questions to investigate!\n",
    "\n",
    "The focus here is on \"explore\" -- you might not find anything of particular interest, but don't let that discourage you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploratory vs. Explanatory Data Analysis \n",
    "\n",
    "> **Exploratory analysis** is what you do to get familiar with the data. You may start out with a hypothesis or question, or you may just really be delving into the data to determine what might be interesting about it. Exploratory analysis is the process of turning over 100 rocks to find perhaps 1 or 2 precious gemstones.\n",
    ">\n",
    "> **Explanatory analysis** is what happens when you have something specific you want to show an audience - probably about those 1 or 2 precious gemstones. In my blogging and writing, I tend to focus mostly on this latter piece, explanatory analysis, when you've already gone through the exploratory analysis and from this have determined something specific you want to communicate to a given audience: in other words, when you want to tell a story with data.\n",
    "\n",
    "- Cole Nussbaumer Knaflic, [exploratory vs. explanatory analysis](http://www.storytellingwithdata.com/blog/2014/04/exploratory-vs-explanatory-analysis)\n",
    "\n",
    "### Choose one visual to explain:\n",
    "\n",
    "Now that you've performed an exploratory data analysis, choose a visual (or 1-3 related visuals) to frame as _explanatory_. This can be a visual you created above, or you can create a new visual. For this visual, make sure the visuals are formatted clearly, and provide a one to two paragraph explanation/interpretation of the visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
